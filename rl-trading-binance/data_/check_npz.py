# data/check_npz.py

import numpy as np
import os
import sys
from loguru import logger
import tabulate
from datetime import datetime

from collections import defaultdict
import warnings
from typing import Dict, Any, List, Optional, Tuple

# –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è NumPy –æ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ —Å NaN
warnings.filterwarnings("ignore", category=RuntimeWarning)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞ —Å —Ü–≤–µ—Ç–∞–º–∏ –∏ —ç–º–æ–¥–∑–∏
log_dir = "logs"
logger.remove()
logger.add(
    sys.stderr,
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{function}</cyan>:<yellow>{line}</yellow> - <level>{message}</level>",
    level="INFO",
    colorize=True
)
logger.add(
    f"{log_dir}/check_npz_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log",
    rotation="10 MB",
    retention="30 days",
    format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {function}:{line} - {message}",
    level="DEBUG"
)



class NPZValidator:
    """–ö–ª–∞—Å—Å –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ .npz —Ñ–∞–π–ª–æ–≤ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–æ–≤"""

    def __init__(self):
        self.validation_results = {}
        self.files_to_check = [
            'train_data.npz',
            'val_data.npz',
            'test_data.npz',
            'backtest_data.npz'
        ]
        self.required_arrays = {
            'train_data.npz': ['X_train', 'y_train'],
            'val_data.npz': ['X_val', 'y_val'],
            'test_data.npz': ['X_test', 'y_test'],
            'backtest_data.npz': ['X_backtest', 'y_backtest', 'timestamps']
        }
        self.dataset_types = {
            'train_data.npz': '–û–±—É—á–∞—é—â–∏–π –Ω–∞–±–æ—Ä',
            'val_data.npz': '–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä',
            'test_data.npz': '–¢–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä',
            'backtest_data.npz': '–ë—ç–∫—Ç–µ—Å—Ç'
        }

    def validate_file(self, file_path: str) -> Dict[str, Any]:
        """–ü–æ–ª–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º"""
        if not os.path.exists(file_path):
            logger.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
            return {
                'status': 'not_found',
                'errors': [f"–§–∞–π–ª –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"],
                'file': file_path
            }

        logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é: {file_path}")
        results = {
            'status': 'valid',
            'file': file_path,
            'type': self.dataset_types.get(file_path, '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø'),
            'arrays': {},
            'warnings': [],
            'errors': [],
            'stats': {}
        }

        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª
            with np.load(file_path, allow_pickle=True) as data:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –º–∞—Å—Å–∏–≤–æ–≤
                required = self.required_arrays.get(file_path, [])
                for array_name in required:
                    if array_name not in data.files:
                        error_msg = f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –º–∞—Å—Å–∏–≤: {array_name}"
                        results['errors'].append(error_msg)
                        results['status'] = 'invalid'
                        logger.error(error_msg)

                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –º–∞—Å—Å–∏–≤ –≤ —Ñ–∞–π–ª–µ
                for key in data.files:
                    array = data[key]
                    shape = array.shape
                    dtype = str(array.dtype)

                    # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–∞—Å—Å–∏–≤–µ
                    array_info = {
                        'shape': shape,
                        'dtype': dtype,
                        'size': array.size,
                        'ndim': array.ndim,
                        'contains_nan': False,
                        'contains_inf': False,
                        'min': None,
                        'max': None,
                        'mean': None,
                        'std': None
                    }

                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN –∏ inf —Ç–æ–ª—å–∫–æ –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö —Ç–∏–ø–æ–≤
                    if np.issubdtype(array.dtype, np.number):
                        try:
                            array_info['contains_nan'] = np.isnan(array).any()
                            array_info['contains_inf'] = np.isinf(array).any()

                            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö –º–∞—Å—Å–∏–≤–æ–≤ –∏–ª–∏ –ø–µ—Ä–≤—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
                            if array.size > 0:
                                # –î–ª—è –±–æ–ª—å—à–∏—Ö –º–∞—Å—Å–∏–≤–æ–≤ –±–µ—Ä–µ–º –≤—ã–±–æ—Ä–∫—É
                                if array.size > 10000:
                                    # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è —Å–ª—É—á–∞–π–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏
                                    indices = np.random.choice(array.size, size=min(1000, array.size), replace=False)
                                    sample = array.flatten()[indices]
                                else:
                                    sample = array.flatten()

                                # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                                array_info['min'] = float(np.min(sample))
                                array_info['max'] = float(np.max(sample))
                                array_info['mean'] = float(np.mean(sample))
                                array_info['std'] = float(np.std(sample))
                        except Exception as e:
                            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã—á–∏—Å–ª–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è {key}: {str(e)}")

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                    results['arrays'][key] = array_info

                    # –ü—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ –ø—Ä–æ–±–ª–µ–º—ã
                    if array.size == 0:
                        warning = f"–ú–∞—Å—Å–∏–≤ '{key}' –ø—É—Å—Ç–æ–π"
                        results['warnings'].append(warning)
                        logger.warning(warning)

                    if array_info['contains_nan']:
                        error = f"–ú–∞—Å—Å–∏–≤ '{key}' —Å–æ–¥–µ—Ä–∂–∏—Ç NaN –∑–Ω–∞—á–µ–Ω–∏—è"
                        results['errors'].append(error)
                        results['status'] = 'invalid'
                        logger.error(error)

                    if array_info['contains_inf']:
                        error = f"–ú–∞—Å—Å–∏–≤ '{key}' —Å–æ–¥–µ—Ä–∂–∏—Ç –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è"
                        results['errors'].append(error)
                        results['status'] = 'invalid'
                        logger.error(error)

                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö
                if 'train' in file_path and 'train_data.npz' == file_path:
                    self._validate_train_data(file_path, data, results)
                elif 'test' in file_path and 'test_data.npz' == file_path:
                    self._validate_test_data(file_path, data, results)
                elif 'backtest' in file_path and 'backtest_data.npz' == file_path:
                    self._validate_backtest_data(file_path, data, results)

                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ñ–∞–π–ª—É
                results['stats'] = {
                    'total_arrays': len(data.files),
                    'valid_arrays': len(data.files) - len(results['errors']),
                    'has_X': any('X' in key for key in data.files),
                    'has_y': any('y' in key for key in data.files)
                }

                return results

        except Exception as e:
            error_msg = f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {str(e)}"
            results['errors'].append(error_msg)
            results['status'] = 'error'
            logger.exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ {file_path}")
            return results

    def _validate_train_data(self, file_path: str, data: np.lib.npyio.NpzFile, results: Dict[str, Any]) -> None:
        """–°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        if 'X_train' in data:
            X = data['X_train']
            if X.ndim != 2:
                warning = "X_train –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¥–≤—É–º–µ—Ä–Ω—ã–º –º–∞—Å—Å–∏–≤–æ–º (–æ–±—Ä–∞–∑—Ü—ã √ó –ø—Ä–∏–∑–Ω–∞–∫–∏)"
                results['warnings'].append(warning)
                logger.warning(warning)

            if X.size == 0:
                error = "X_train –ø—É—Å—Ç–æ–π - –Ω–µ—Ç –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö"
                results['errors'].append(error)
                results['status'] = 'invalid'
                logger.error(error)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—Ä–∞–∑—Ü–æ–≤
            if X.shape[0] < 100:
                warning = f"–ù–µ–±–æ–ª—å—à–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—É—á–∞—é—â–∏—Ö –æ–±—Ä–∞–∑—Ü–æ–≤: {X.shape[0]} (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è > 100)"
                results['warnings'].append(warning)
                logger.warning(warning)

    def _validate_test_data(self, file_path: str, data: np.lib.npyio.NpzFile, results: Dict[str, Any]) -> None:
        """–°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –æ–±—É—á–∞—é—â–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏, –µ—Å–ª–∏ –æ–Ω–∏ —É–∂–µ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω—ã
        if 'train_data.npz' in self.validation_results:
            train_result = self.validation_results['train_data.npz']
            if train_result.get('status') == 'valid' and 'X_train' in train_result.get('arrays', {}):
                if 'X_test' in data:
                    X_test = data['X_test']
                    train_shape = train_result['arrays']['X_train']['shape']

                    if X_test.ndim >= 2 and train_shape and len(train_shape) >= 2:
                        if X_test.shape[1] != train_shape[1]:
                            error = f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ X_test ({X_test.shape[1]}) –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å X_train ({train_shape[1]})"
                            results['errors'].append(error)
                            results['status'] = 'invalid'
                            logger.error(error)

    def _validate_backtest_data(self, file_path: str, data: np.lib.npyio.NpzFile, results: Dict[str, Any]) -> None:
        """–°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∞"""
        if 'timestamps' in data:
            timestamps = data['timestamps']
            if timestamps.ndim != 1:
                warning = "timestamps –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ–¥–Ω–æ–º–µ—Ä–Ω—ã–º –º–∞—Å—Å–∏–≤–æ–º"
                results['warnings'].append(warning)
                logger.warning(warning)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø–æ—Ä—è–¥–æ–∫
            if timestamps.size > 1 and np.issubdtype(timestamps.dtype, np.datetime64) or np.issubdtype(timestamps.dtype,
                                                                                                       np.number):
                try:
                    is_sorted = np.all(timestamps[:-1] <= timestamps[1:])
                    if not is_sorted:
                        warning = "timestamps –Ω–µ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é"
                        results['warnings'].append(warning)
                        logger.warning(warning)
                except Exception as e:
                    logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫—É timestamps: {str(e)}")

    def validate_all_files(self) -> None:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        logger.info("–ó–∞–ø—É—Å–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –¥–∞–Ω–Ω—ã—Ö")
        logger.info("========================================")

        # –°–Ω–∞—á–∞–ª–∞ –≤–∞–ª–∏–¥–∏—Ä—É–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã
        for file in self.files_to_check:
            logger.info(f"\n{'=' * 30} –í–ê–õ–ò–î–ê–¶–ò–Ø: {file} {'=' * 30}")
            self.validation_results[file] = self.validate_file(file)

        # –¢–µ–ø–µ—Ä—å –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –º–µ–∂–¥—É —Ñ–∞–π–ª–∞–º–∏ (–ø–æ—Å–ª–µ —Ç–æ–≥–æ, –∫–∞–∫ –≤—Å–µ —Ñ–∞–π–ª—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã)
        self._check_consistency()

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
        self._generate_detailed_report()

    def _check_consistency(self) -> None:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É —Ä–∞–∑–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏"""
        logger.info("\n–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É –Ω–∞–±–æ—Ä–∞–º–∏...")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –º–µ–∂–¥—É train –∏ –¥—Ä—É–≥–∏–º–∏ –Ω–∞–±–æ—Ä–∞–º–∏
        if 'train_data.npz' in self.validation_results and self.validation_results['train_data.npz'].get(
                'status') == 'valid':
            train_info = self.validation_results['train_data.npz']

            if 'X_train' in train_info.get('arrays', {}):
                train_shape = train_info['arrays']['X_train']['shape']

                for file in ['val_data.npz', 'test_data.npz', 'backtest_data.npz']:
                    if file in self.validation_results and self.validation_results[file].get('status') == 'valid':
                        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è –º–∞—Å—Å–∏–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
                        prefix = file.split('_')[0]
                        x_name = f"X_{prefix}"

                        if x_name in self.validation_results[file]['arrays']:
                            test_shape = self.validation_results[file]['arrays'][x_name]['shape']

                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –º–∞—Å—Å–∏–≤—ã –¥–≤—É–º–µ—Ä–Ω—ã–µ
                            if len(test_shape) >= 2 and len(train_shape) >= 2:
                                if test_shape[1] != train_shape[1]:
                                    msg = f"–ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {file} –∏–º–µ–µ—Ç {test_shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –∞ train –∏–º–µ–µ—Ç {train_shape[1]}"
                                    self.validation_results[file]['errors'].append(msg)
                                    self.validation_results[file]['status'] = 'invalid'
                                    logger.error(msg)

    def _generate_detailed_report(self) -> None:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º tabulate"""
        logger.info("\n\nüìä –î–ï–¢–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –ü–û –í–ê–õ–ò–î–ê–¶–ò–ò –î–ê–ù–ù–´–•")
        logger.info("========================================")

        # 1. –û–±—â–∞—è —Å–≤–æ–¥–∫–∞ –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º
        self._generate_summary_section()

        # 2. –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –∫–∞–∂–¥–æ–º—É —Ñ–∞–π–ª—É
        for file, result in self.validation_results.items():
            self._generate_file_report(file, result)

        # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –º–µ–∂–¥—É –Ω–∞–±–æ—Ä–∞–º–∏
        self._generate_consistency_report()

        # 4. –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        self._generate_recommendations()

    def _generate_summary_section(self) -> None:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã –ø–æ –≤—Å–µ–º —Ñ–∞–π–ª–∞–º"""
        logger.info("\n1. –û–ë–©–ê–Ø –°–í–û–î–ö–ê –ü–û –í–ê–õ–ò–î–ê–¶–ò–ò:")

        summary_data = []
        for file, result in self.validation_results.items():
            status = result.get('status', 'error')
            if status == 'valid':
                status_display = "‚úÖ –í–∞–ª–∏–¥–µ–Ω"
                status_color = "success"
            elif status == 'invalid':
                status_display = "‚ùå –ù–µ–≤–∞–ª–∏–¥–µ–Ω"
                status_color = "error"
            elif status == 'not_found':
                status_display = "‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω"
                status_color = "warning"
            else:
                status_display = "üêû –û—à–∏–±–∫–∞"
                status_color = "error"

            # –ü–æ–¥—Å—á–µ—Ç –æ—à–∏–±–æ–∫ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
            error_count = len(result.get('errors', []))
            warning_count = len(result.get('warnings', []))

            summary_data.append([
                file,
                status_display,
                self.dataset_types.get(file, 'N/A'),
                f"{result.get('stats', {}).get('total_arrays', 0)}",
                f"{'‚ùå ' + str(error_count) if error_count > 0 else '‚úÖ 0'}",
                f"{'‚ö†Ô∏è ' + str(warning_count) if warning_count > 0 else '0'}"
            ])

        # –í—ã–≤–æ–¥ —Å–≤–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
        headers = ["–§–∞–π–ª", "–°—Ç–∞—Ç—É—Å", "–¢–∏–ø –Ω–∞–±–æ—Ä–∞", "–ú–∞—Å—Å–∏–≤—ã", "–û—à–∏–±–∫–∏", "–ü—Ä–µ–¥—É–ø—Ä."]
        table = tabulate.tabulate(
            summary_data,
            headers=headers,
            tablefmt="rounded_grid",
            stralign="center"
        )
        logger.opt(colors=True).info(f"\n{table}")

    def _generate_file_report(self, file: str, result: Dict[str, Any]) -> None:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
        if result.get('status') == 'not_found':
            logger.warning(f"\n\n‚ö†Ô∏è –§–ê–ô–õ {file} –ù–ï –ù–ê–ô–î–ï–ù")
            logger.info("  ‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏ –µ–≥–æ –Ω–∞–ª–∏—á–∏–µ –≤ —Ä–∞–±–æ—á–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏")
            return

        status = result.get('status', 'error')
        status_emoji = "‚úÖ" if status == 'valid' else "‚ùå"
        logger.info(f"\n\n{status_emoji} –î–ï–¢–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢: {file} ({self.dataset_types.get(file, 'N/A')})")

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ç–∞—Ç—É—Å–µ
        if status == 'valid':
            logger.success("‚úì –°—Ç–∞—Ç—É—Å: –í—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")
        else:
            logger.error(f"‚úó –°—Ç–∞—Ç—É—Å: {len(result.get('errors', []))} –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫")

        # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∞–π–ª–µ
        logger.info("\nüìå –û–°–ù–û–í–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:")
        stats = result.get('stats', {})
        logger.info(f"  ‚Ä¢ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–∞—Å—Å–∏–≤–æ–≤: {stats.get('total_arrays', 0)}")
        logger.info(f"  ‚Ä¢ –ù–∞–ª–∏—á–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (X): {'–î–∞' if stats.get('has_X') else '–ù–µ—Ç'}")
        logger.info(f"  ‚Ä¢ –ù–∞–ª–∏—á–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π (y): {'–îa' if stats.get('has_y') else '–ù–µ—Ç'}")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –º–∞—Å—Å–∏–≤–æ–≤
        required = self.required_arrays.get(file, [])
        missing = []
        if 'arrays' in result:
            missing = [arr for arr in required if arr not in result['arrays']]

        if missing:
            logger.warning(f"  ‚Ä¢ –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –º–∞—Å—Å–∏–≤—ã: {', '.join(missing)}")
        else:
            logger.success("  ‚Ä¢ –í—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –º–∞—Å—Å–∏–≤—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç")

        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–∞–∂–¥–æ–º –º–∞—Å—Å–∏–≤–µ
        if result.get('arrays'):
            logger.info("\nüìã –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ú–ê–°–°–ò–í–ê–•:")
            array_data = []
            for name, info in result['arrays'].items():
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –º–∞—Å—Å–∏–≤–∞
                status = "‚úÖ"
                if info.get('contains_nan'):
                    status = "‚ùå NaN"
                elif info.get('contains_inf'):
                    status = "‚ùå Inf"
                elif info.get('size', 0) == 0:
                    status = "‚ö†Ô∏è –ü—É—Å—Ç–æ–π"

                # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
                shape_str = "√ó".join(map(str, info['shape'])) if info['shape'] else "0"
                dtype_str = info['dtype']
                size_str = f"{info['size']:,}".replace(',', ' ')

                # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞
                stats_str = ""
                if info.get('min') is not None and info.get('max') is not None:
                    stats_str = f"min={info['min']:.2f}, max={info['max']:.2f}"

                array_data.append([
                    name,
                    status,
                    shape_str,
                    dtype_str,
                    size_str,
                    stats_str
                ])

            # –í—ã–≤–æ–¥–∏–º —Ç–∞–±–ª–∏—Ü—É —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –º–∞—Å—Å–∏–≤–∞—Ö
            headers = ["–ò–º—è", "–°—Ç–∞—Ç—É—Å", "–§–æ—Ä–º–∞", "–¢–∏–ø", "–†–∞–∑–º–µ—Ä", "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"]
            table = tabulate.tabulate(
                array_data,
                headers=headers,
                tablefmt="simple_outline",
                stralign="left",
                maxcolwidths=[15, 8, 15, 10, 10, 30]
            )
            logger.info(f"\n{table}")

        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ—à–∏–±–æ–∫
        if result.get('errors'):
            logger.error(f"\nüö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –û–®–ò–ë–ö–ò ({len(result['errors'])}):")
            for i, error in enumerate(result['errors'], 1):
                logger.error(f"  {i}. {error}")

        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
        if result.get('warnings'):
            logger.warning(f"\n‚ö†Ô∏è –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–Ø ({len(result['warnings'])}):")
            for i, warning in enumerate(result['warnings'], 1):
                logger.warning(f"  {i}. {warning}")

        # –ü—Ä–µ–≤—å—é –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –º–∞—Å—Å–∏–≤–æ–≤
        self._generate_data_preview(file, result)

    def _generate_data_preview(self, file: str, result: Dict[str, Any]) -> None:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–≤—å—é –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –º–∞—Å—Å–∏–≤–æ–≤"""
        # –ò—â–µ–º –ø–æ–¥—Ö–æ–¥—è—â–∏–π –º–∞—Å—Å–∏–≤ –¥–ª—è –ø—Ä–µ–≤—å—é (–ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–æ X_*)
        preview_array = None
        preview_name = None

        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª
        try:
            with np.load(file, allow_pickle=True) as data:
                for name in data.files:
                    if 'X' in name and data[name].ndim == 2 and data[name].size > 0:
                        preview_array = data[name]
                        preview_name = name
                        break

                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ X_*, –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ª—é–±–æ–π 2D –º–∞—Å—Å–∏–≤
                if preview_array is None:
                    for name in data.files:
                        if data[name].ndim == 2 and data[name].size > 0:
                            preview_array = data[name]
                            preview_name = name
                            break

                if preview_array is not None and preview_array.size > 0:
                    logger.info(f"\nüîç –ü–†–ï–í–¨–Æ –î–ê–ù–ù–´–• ({preview_name}):")

                    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ –∏ –ø–µ—Ä–≤—ã–µ 4 —Å—Ç–æ–ª–±—Ü–∞
                    rows = min(5, preview_array.shape[0])
                    cols = min(4, preview_array.shape[1])
                    sample = preview_array[:rows, :cols]

                    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
                    formatted_data = []
                    for i in range(rows):
                        row = []
                        for x in sample[i]:
                            if isinstance(x, (float, np.floating)):
                                row.append(f"{x:.4f}")
                            else:
                                row.append(str(x))
                        formatted_data.append(row)

                    # –°–æ–∑–¥–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
                    headers = [f"Col {i}" for i in range(cols)]

                    # –í—ã–≤–æ–¥–∏–º —Ç–∞–±–ª–∏—Ü—É
                    table = tabulate.tabulate(
                        formatted_data,
                        headers=headers,
                        tablefmt="rounded_outline",
                        stralign="right"
                    )
                    logger.info(f"\n{table}")

                    if rows < preview_array.shape[0] or cols < preview_array.shape[1]:
                        logger.info(f"\n  ‚Ä¢ –û—Ç–æ–±—Ä–∞–∂–µ–Ω–æ {rows} —Å—Ç—Ä–æ–∫ √ó {cols} —Å—Ç–æ–ª–±—Ü–æ–≤")
                        logger.info(f"  ‚Ä¢ –û–±—â–∞—è —Ñ–æ—Ä–º–∞ –¥–∞–Ω–Ω—ã—Ö: {preview_array.shape}")
        except Exception as e:
            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–≤—å—é –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {file}: {str(e)}")

    def _generate_consistency_report(self) -> None:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É –Ω–∞–±–æ—Ä–∞–º–∏"""
        logger.info("\n\nüîó –ü–†–û–í–ï–†–ö–ê –°–û–ì–õ–ê–°–û–í–ê–ù–ù–û–°–¢–ò –ú–ï–ñ–î–£ –ù–ê–ë–û–†–ê–ú–ò –î–ê–ù–ù–´–•")
        logger.info("========================================")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –º–µ–∂–¥—É train –∏ –¥—Ä—É–≥–∏–º–∏ –Ω–∞–±–æ—Ä–∞–º–∏
        if 'train_data.npz' in self.validation_results:
            train_res = self.validation_results['train_data.npz']
            if train_res.get('status') == 'valid' and 'X_train' in train_res.get('arrays', {}):
                train_shape = train_res['arrays']['X_train']['shape']
                logger.success(f"‚úì –û–±—É—á–∞—é—â–∏–π –Ω–∞–±–æ—Ä: {train_shape[0]} –æ–±—Ä–∞–∑—Ü–æ–≤, {train_shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

                # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å –¥—Ä—É–≥–∏–º–∏ –Ω–∞–±–æ—Ä–∞–º–∏
                comparisons = []
                for file in ['val_data.npz', 'test_data.npz', 'backtest_data.npz']:
                    if file in self.validation_results:
                        file_res = self.validation_results[file]
                        if file_res.get('status') == 'valid':
                            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è –º–∞—Å—Å–∏–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                            prefix = file.split('_')[0]
                            x_name = f"X_{prefix}"

                            if x_name in file_res.get('arrays', {}):
                                test_shape = file_res['arrays'][x_name]['shape']

                                if len(test_shape) >= 2 and len(train_shape) >= 2:
                                    if test_shape[1] == train_shape[1]:
                                        comparisons.append([
                                            self.dataset_types[file],
                                            f"{test_shape[0]}",
                                            f"{test_shape[1]}",
                                            "‚úÖ –°–æ–≤–ø–∞–¥–∞–µ—Ç"
                                        ])
                                    else:
                                        comparisons.append([
                                            self.dataset_types[file],
                                            f"{test_shape[0]}",
                                            f"{test_shape[1]}",
                                            f"‚ùå –ù–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç ({train_shape[1]} –≤ train)"
                                        ])

                # –í—ã–≤–æ–¥–∏–º —Ç–∞–±–ª–∏—Ü—É —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                if comparisons:
                    headers = ["–ù–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö", "–û–±—Ä–∞–∑—Ü—ã", "–ü—Ä–∏–∑–Ω–∞–∫–∏", "–°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å"]
                    table = tabulate.tabulate(
                        comparisons,
                        headers=headers,
                        tablefmt="rounded_grid",
                        stralign="center"
                    )
                    logger.info(f"\n–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –æ–±—É—á–∞—é—â–∏–º –Ω–∞–±–æ—Ä–æ–º:\n{table}")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–æ–≤
        sizes = {}
        for file in ['train_data.npz', 'val_data.npz', 'test_data.npz']:
            if file in self.validation_results and self.validation_results[file].get('status') == 'valid':
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è –º–∞—Å—Å–∏–≤–∞
                prefix = file.split('_')[0]
                x_name = f"X_{prefix}"

                if x_name in self.validation_results[file].get('arrays', {}):
                    shape = self.validation_results[file]['arrays'][x_name]['shape']
                    sizes[file] = shape[0]

        if len(sizes) >= 2:
            logger.info("\nüìä –°–û–û–¢–ù–û–®–ï–ù–ò–ï –†–ê–ó–ú–ï–†–û–í –ù–ê–ë–û–†–û–í:")
            total = sum(sizes.values())
            ratios = []
            for file, size in sizes.items():
                ratio = (size / total) * 100
                set_type = self.dataset_types[file].replace(" –Ω–∞–±–æ—Ä", "")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–º –∑–Ω–∞—á–µ–Ω–∏—è–º
                if "test" in file and (10 <= ratio <= 20):
                    status = "‚úÖ"
                elif "val" in file and (10 <= ratio <= 20):
                    status = "‚úÖ"
                elif "train" in file and (60 <= ratio <= 80):
                    status = "‚úÖ"
                else:
                    status = "‚ö†Ô∏è"

                ratios.append([set_type, f"{size:,}".replace(',', ' '), f"{ratio:.1f}% ({status})"])

            headers = ["–¢–∏–ø", "–†–∞–∑–º–µ—Ä", "–î–æ–ª—è –æ—Ç –æ–±—â–µ–≥–æ"]
            table = tabulate.tabulate(
                ratios,
                headers=headers,
                tablefmt="rounded_outline",
                stralign="center"
            )
            logger.info(f"\n{table}")

    def _generate_recommendations(self) -> None:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
        logger.info("\n\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –£–õ–£–ß–®–ï–ù–ò–Æ –î–ê–ù–ù–´–•")
        logger.info("========================================")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –Ω–∞–±–æ—Ä–æ–≤
        required_sets = ['train_data.npz', 'val_data.npz', 'test_data.npz']
        missing_sets = [s for s in required_sets if self.validation_results.get(s, {}).get('status') != 'valid']

        if missing_sets:
            logger.warning(f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∏–ª–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω—ã –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö: {', '.join(missing_sets)}")
            logger.info("  ‚Ä¢ –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Å–æ–∑–¥–∞—Ç—å –≤—Å–µ —Ç—Ä–∏ –Ω–∞–±–æ—Ä–∞: –æ–±—É—á–∞—é—â–∏–π, –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –∏ —Ç–µ—Å—Ç–æ–≤—ã–π")
        else:
            logger.success("‚úì –í—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –∏ –≤–∞–ª–∏–¥–Ω—ã")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —É—Ç–µ—á–∫—É –¥–∞–Ω–Ω—ã—Ö
        has_timestamps = 'backtest_data.npz' in self.validation_results and 'timestamps' in self.validation_results[
            'backtest_data.npz'].get('arrays', {})
        if has_timestamps and 'train_data.npz' in self.validation_results:
            logger.info("\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —É—Ç–µ—á–∫—É –¥–∞–Ω–Ω—ã—Ö:")
            logger.info(
                "  ‚Ä¢ –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –≤ –æ–±—É—á–∞—é—â–µ–º –Ω–∞–±–æ—Ä–µ –ø—Ä–µ–¥—à–µ—Å—Ç–≤—É—é—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–º –º–µ—Ç–∫–∞–º –≤ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ")
            logger.info("  ‚Ä¢ –î–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ —Å–æ–±–ª—é–¥–∞—Ç—å —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø–æ—Ä—è–¥–æ–∫ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤
        if 'train_data.npz' in self.validation_results:
            train_res = self.validation_results['train_data.npz']
            if 'y_train' in train_res.get('arrays', {}):
                try:
                    with np.load('train_data.npz', allow_pickle=True) as data:
                        if 'y_train' in data:
                            y = data['y_train']
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∑–∞–¥–∞—á–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π (–º–∞–ª–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π)
                            if np.issubdtype(y.dtype, np.integer) or len(np.unique(y)) < 20:
                                unique, counts = np.unique(y, return_counts=True)
                                balance = counts / np.sum(counts)

                                logger.info("\n‚öñÔ∏è –ë–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤ –≤ –æ–±—É—á–∞—é—â–µ–º –Ω–∞–±–æ—Ä–µ:")
                                class_data = []
                                for cls, count, pct in zip(unique, counts, balance):
                                    status = "‚úÖ" if 0.2 <= pct <= 0.8 else "‚ö†Ô∏è"
                                    class_data.append([f"–ö–ª–∞—Å—Å {cls}", f"{count}", f"{pct:.1%} ({status})"])

                                headers = ["–ö–ª–∞—Å—Å", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", "–î–æ–ª—è"]
                                table = tabulate.tabulate(
                                    class_data,
                                    headers=headers,
                                    tablefmt="simple",
                                    stralign="center"
                                )
                                logger.info(f"\n{table}")
                                logger.info(
                                    "  ‚Ä¢ –î–ª—è –∑–∞–¥–∞—á –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 20-80%")
                except Exception as e:
                    logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤: {str(e)}")

        # –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        logger.info("\nüìå –û–ë–©–ò–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
        logger.info("  ‚Ä¢ –ü–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º —É–±–µ–¥–∏—Ç–µ—Å—å –≤ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ —É—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É –Ω–∞–±–æ—Ä–∞–º–∏")
        logger.info("  ‚Ä¢ –î–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø—Ä–∏–º–µ–Ω–∏—Ç–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—É—á–∞—é—â–µ–≥–æ –Ω–∞–±–æ—Ä–∞")
        logger.info("  ‚Ä¢ –î–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ —É–±–µ–¥–∏—Ç–µ—Å—å –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö")
        logger.info("  ‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ –æ–±—É—á–∞—é—â–µ–º –∏ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–∞—Ö")
        logger.info("  ‚Ä¢ –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ç–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–µ–Ω –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")


def main() -> None:
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
    try:
        import loguru
        import tabulate
    except ImportError:
        logger.warning("–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫ loguru –∏ tabulate...")
        try:
            os.system("pip install loguru tabulate --quiet")
            from loguru import logger
            import tabulate
        except Exception as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏: {str(e)}")
            return

    # –ó–∞–ø—É—Å–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    validator = NPZValidator()
    validator.validate_all_files()


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        logger.warning("\n\n–ü—Ä–æ–≥—Ä–∞–º–º–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º (Ctrl+C)")
    except Exception as e:
        logger.exception("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –ø—Ä–æ–≥—Ä–∞–º–º–µ")